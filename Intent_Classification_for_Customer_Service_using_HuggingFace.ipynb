{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akankshakusf/Project-DP-Intent-Classification-for-Customer-Service-using-HuggingFace-/blob/master/Intent_Classification_for_Customer_Service_using_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "_nVmTxhq5GuL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3v_254qfi_uC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.37.2 tensorflow==2.15.0"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwjozWCj5KG2",
        "outputId": "387ec699-9c16-4164-eca0-9bb006bfc9c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.37.2\n",
            "  Downloading transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.37.2) (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.13.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy>=1.17 (from transformers==4.37.2)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.13.2)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.71.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2) (2025.3.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.37.2) (2025.1.31)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "Downloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tokenizers, transformers, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 numpy-1.26.4 protobuf-4.25.7 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tokenizers-0.15.2 transformers-4.37.2 wrapt-1.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15.0 --no-cache-dir --force-reinstall\n",
        "!pip install tensorflow_text==2.15.0 --no-cache-dir --force-reinstall"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsLhieOm5S9Y",
        "outputId": "1c4e2ea4-87a8-4918-a51d-7036c31ffd2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.15.0)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.15.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow==2.15.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15.0)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.15.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow==2.15.0)\n",
            "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.15.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m182.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow==2.15.0)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.15.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow==2.15.0)\n",
            "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow==2.15.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.15.0)\n",
            "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.15.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.15.0)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.15.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m193.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m141.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m228.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m237.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m165.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m239.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m206.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m200.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m238.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m266.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m299.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m187.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m213.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m244.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m208.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m198.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
            "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m231.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m250.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m275.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m285.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m218.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m271.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m271.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m234.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m295.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m289.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m214.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.7\n",
            "    Uninstalling protobuf-4.25.7:\n",
            "      Successfully uninstalled protobuf-4.25.7\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorstore 0.1.73 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "langchain-core 0.3.55 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-auth-2.39.0 google-auth-oauthlib-1.2.2 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-2.15.0 libclang-18.1.1 markdown-3.8 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-25.0 protobuf-4.25.7 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-79.0.1 six-1.17.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.0.1 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "six"
                ]
              },
              "id": "0f92dd2ce90b46938bc4b7140a009465"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text==2.15.0\n",
            "  Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-hub>=0.13.0 (from tensorflow_text==2.15.0)\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tensorflow<2.16,>=2.15.0 (from tensorflow_text==2.15.0)\n",
            "  Downloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting setuptools (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.13.0->tensorflow_text==2.15.0)\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.13.0->tensorflow_text==2.15.0)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow_text==2.15.0)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading tensorflow_text-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m227.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m240.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m256.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m205.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m292.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m267.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m298.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m290.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m307.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m312.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m258.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m300.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m289.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m334.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m315.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m185.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
            "Downloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m142.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m224.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
            "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.2/106.2 kB\u001b[0m \u001b[31m289.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m259.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m315.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m251.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m164.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m280.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m206.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m168.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m268.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m255.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m249.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: libclang, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, MarkupSafe, markdown, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, ml-dtypes, h5py, google-pasta, astunparse, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow, tf-keras, tensorflow-hub, tensorflow_text\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.0.1\n",
            "    Uninstalling termcolor-3.0.1:\n",
            "      Successfully uninstalled termcolor-3.0.1\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 79.0.1\n",
            "    Uninstalling setuptools-79.0.1:\n",
            "      Successfully uninstalled setuptools-79.0.1\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.7\n",
            "    Uninstalling protobuf-4.25.7:\n",
            "      Successfully uninstalled protobuf-4.25.7\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.39.0\n",
            "    Uninstalling google-auth-2.39.0:\n",
            "      Successfully uninstalled google-auth-2.39.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.18.0\n",
            "    Uninstalling tf_keras-2.18.0:\n",
            "      Successfully uninstalled tf_keras-2.18.0\n",
            "  Attempting uninstall: tensorflow-hub\n",
            "    Found existing installation: tensorflow-hub 0.16.1\n",
            "    Uninstalling tensorflow-hub-0.16.1:\n",
            "      Successfully uninstalled tensorflow-hub-0.16.1\n",
            "  Attempting uninstall: tensorflow_text\n",
            "    Found existing installation: tensorflow-text 2.18.1\n",
            "    Uninstalling tensorflow-text-2.18.1:\n",
            "      Successfully uninstalled tensorflow-text-2.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\n",
            "langchain-core 0.3.55 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, but you have tf-keras 2.15.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.1 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.37.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.2.2 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-auth-2.39.0 google-auth-oauthlib-1.2.2 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-2.15.0 libclang-18.1.1 markdown-3.8 ml-dtypes-0.3.2 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.4.0 packaging-25.0 protobuf-4.25.7 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.3 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-79.0.1 six-1.17.0 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 tensorflow-hub-0.16.1 tensorflow-io-gcs-filesystem-0.37.1 tensorflow_text-2.15.0 termcolor-3.0.1 tf-keras-2.15.1 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "six"
                ]
              },
              "id": "be8bdee28ab04f75b4c0be7e6b0812f4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  datasets #transformers"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fmxQroN5eJT",
        "outputId": "89590b3b-2205-431b-cd6b-e7272241d6a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if correct versions are installed\n",
        "import keras\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "import transformers\n",
        "print(\"Transformers version:\", transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmP5PLQD5h5r",
        "outputId": "0fc1b2ee-bf9e-46d3-ea6e-1587d9eee3d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras version: 2.15.0\n",
            "TensorFlow version: 2.15.1\n",
            "Transformers version: 4.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "WhQDUPP75qQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#general packages import\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import pathlib\n",
        "import io\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from numpy import random\n",
        "from PIL import Image\n",
        "\n",
        "#tensorflow imports\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Dense, Flatten, Input, InputLayer, BatchNormalization,Dropout, LayerNormalization\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, categorical_crossentropy, sparse_categorical_crossentropy\n",
        "from tensorflow.keras.metrics import Accuracy, TopKCategoricalAccuracy, CategoricalAccuracy, SparseCategoricalAccuracy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive, files\n",
        "from datasets import load_dataset\n",
        "from transformers import (BertTokenizer, BertTokenizerFast, TFBertTokenizer, RobertaTokenizerFast, DebertaTokenizerFast,\n",
        "                          DataCollatorWithPadding, TFRobertaForSequenceClassification, TFRobertaForSequenceClassification,\n",
        "                          TFBertModel, create_optimizer)\n",
        "\n"
      ],
      "metadata": {
        "id": "e-2RdxmV5qta"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the batch size\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "yBOTCtxb6nrb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "4fuPLlrMMKKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import dataset from kaggle\n",
        "!pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d bitext/training-dataset-for-chatbotsvirtual-assistants\n",
        "!unzip \"/content/training-dataset-for-chatbotsvirtual-assistants.zip\" -d \"/content/dataset/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0gmHKfMKkd",
        "outputId": "0778a655-ee1c-4df4-e95c-7836001f3f6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Dataset URL: https://www.kaggle.com/datasets/bitext/training-dataset-for-chatbotsvirtual-assistants\n",
            "License(s): copyright-authors\n",
            "Archive:  /content/training-dataset-for-chatbotsvirtual-assistants.zip\n",
            "  inflating: /content/dataset/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample.csv  \n",
            "  inflating: /content/dataset/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample.xlsx  \n",
            "  inflating: /content/dataset/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/LICENSE.txt  \n",
            "  inflating: /content/dataset/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/README.txt  \n",
            "  inflating: /content/dataset/Bitext_Sample_Customer_Service_Training_Dataset/Training/Bitext_Sample_Customer_Service_Training_Dataset.csv  \n",
            "  inflating: /content/dataset/Bitext_Sample_Customer_Service_Training_Dataset/Training/Bitext_Sample_Customer_Service_Training_Dataset.xlsx  \n",
            "  inflating: /content/dataset/Bitext_Sample_Customer_Service_Training_Dataset/Training/LICENSE.txt  \n",
            "  inflating: /content/dataset/Bitext_Sample_Customer_Service_Training_Dataset/Training/README.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "dataset = load_dataset(\"csv\",\n",
        "                       data_files=\"/content/dataset/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample/20000-Utterances-Training-dataset-for-chatbots-virtual-assistant-Bitext-sample.csv\")"
      ],
      "metadata": {
        "id": "f9jw5wgHNq2m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhP7lOHXN-pg",
        "outputId": "b89b4fb9-a73d-4bbd-c8f9-20b781407587"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['flags', 'utterance', 'category', 'intent'],\n",
              "        num_rows: 21534\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check data\n",
        "dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnDeptu_N_p1",
        "outputId": "70111912-2879-4473-fac7-3dec593866fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flags': 'BILC',\n",
              " 'utterance': \"I don't have an online account, what do I have to do to register?\",\n",
              " 'category': 'ACCOUNT',\n",
              " 'intent': 'create_account'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check data\n",
        "dataset['train'][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9peL-vX7ODu-",
        "outputId": "bbdf6e58-06b4-4f88-f456-eaa40924813c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flags': 'BILQZ',\n",
              " 'utterance': 'can you tell me if i can regisger two accounts with a single email address?',\n",
              " 'category': 'ACCOUNT',\n",
              " 'intent': 'create_account'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset))\n",
        "print(type(dataset['train']['intent'])) # its a list of dicts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezopxfi3OmYR",
        "outputId": "9bfa103f-295b-46c1-abc2-fc6479f01316"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'datasets.dataset_dict.DatasetDict'>\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']['intent'] #but we want only unique intents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1YwvgM-Q4w1",
        "outputId": "89a267bc-8a21-44b8-e6e3-52037985889a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " 'create_account',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set(dataset['train']['intent']) #use \"set\" for unique intents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NTvUPBOQwNV",
        "outputId": "e805db9b-9f56-4b51-c71b-ac0e91304785"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cancel_order',\n",
              " 'change_order',\n",
              " 'change_shipping_address',\n",
              " 'check_cancellation_fee',\n",
              " 'check_invoices',\n",
              " 'check_payment_methods',\n",
              " 'check_refund_policy',\n",
              " 'complaint',\n",
              " 'contact_customer_service',\n",
              " 'contact_human_agent',\n",
              " 'create_account',\n",
              " 'delete_account',\n",
              " 'delivery_options',\n",
              " 'delivery_period',\n",
              " 'edit_account',\n",
              " 'get_invoice',\n",
              " 'get_refund',\n",
              " 'newsletter_subscription',\n",
              " 'payment_issue',\n",
              " 'place_order',\n",
              " 'recover_password',\n",
              " 'registration_problems',\n",
              " 'review',\n",
              " 'set_up_shipping_address',\n",
              " 'switch_account',\n",
              " 'track_order',\n",
              " 'track_refund'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of unique intents and find len\n",
        "intents = list(set(dataset['train']['intent']))\n",
        "\n",
        "# we are giving every category a numbers\n",
        "dict_intents = {intents[i]:i for i in range(len(intents))} #replace intent with intent[i]\n",
        "print(dict_intents)\n",
        "print(len(intents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51Jwkc5DOHP9",
        "outputId": "ddff89fb-afd0-4a4a-86ec-d9da13f473b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'place_order': 0, 'track_refund': 1, 'cancel_order': 2, 'set_up_shipping_address': 3, 'edit_account': 4, 'change_shipping_address': 5, 'switch_account': 6, 'delivery_period': 7, 'recover_password': 8, 'change_order': 9, 'get_refund': 10, 'registration_problems': 11, 'delivery_options': 12, 'create_account': 13, 'check_payment_methods': 14, 'complaint': 15, 'contact_customer_service': 16, 'contact_human_agent': 17, 'review': 18, 'newsletter_subscription': 19, 'check_cancellation_fee': 20, 'track_order': 21, 'get_invoice': 22, 'payment_issue': 23, 'check_invoices': 24, 'delete_account': 25, 'check_refund_policy': 26}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*from here we can see that index number of the intents.*\n",
        "- 'place_order': 0,\n",
        "- 'track_refund': 1,\n",
        "- 'cancel_order': 2,\n",
        "- 'set_up_shipping_address': 3,\n",
        "- 'edit_account': 4,\n",
        "- 'change_shipping_address': 5,\n",
        "- 'switch_account': 6,\n",
        "- 'delivery_period': 7,\n",
        "- 'recover_password': 8,\n",
        "- 'change_order': 9,\n",
        "- 'get_refund': 10......and so on"
      ],
      "metadata": {
        "id": "H1vLC6VaR3hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# map above intents to their index numbers\n",
        "def preprocess(dataset):\n",
        "  return {'utterance':dataset['utterance'],\n",
        "          'intent':dict_intents[dataset['intent']]}"
      ],
      "metadata": {
        "id": "9wxoWggjPTmW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call function\n",
        "prep_dataset = dataset.map(preprocess)"
      ],
      "metadata": {
        "id": "mjMSaKubP7hF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This mapping is done so that the model is dealing with numbers rather than strings"
      ],
      "metadata": {
        "id": "sKSsUQwkSeQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#review the dataset\n",
        "prep_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-JEvsS2QFGd",
        "outputId": "3a7479ec-0b7b-4822-9b10-d413c11ef624"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flags': 'BILC',\n",
              " 'utterance': \"I don't have an online account, what do I have to do to register?\",\n",
              " 'category': 'ACCOUNT',\n",
              " 'intent': 13}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- review the intent is numerical values now"
      ],
      "metadata": {
        "id": "ZuGSXKP6TSLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize Data"
      ],
      "metadata": {
        "id": "9HOAlbzfTt-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- reference : https://huggingface.co/microsoft/deberta-base"
      ],
      "metadata": {
        "id": "UdkSl9k7T5eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the model from hugging face\n",
        "model_id = \"microsoft/deberta-base\"\n",
        "\n",
        "#initialize the tokenizer model\n",
        "tokenizer=DebertaTokenizerFast.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "1GT7xUmDTQ2F"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_function(dataset):\n",
        "  return tokenizer(dataset['utterance'],)"
      ],
      "metadata": {
        "id": "Eyh0huy0USnV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize dataset\n",
        "tokenized_dataset = prep_dataset.map(tokenizer_function)"
      ],
      "metadata": {
        "id": "DG3IGP57U2w0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#review data\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apTFZaHwVEJm",
        "outputId": "26f9f295-51f2-40c7-d58a-8387c1ee0ada"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['flags', 'utterance', 'category', 'intent', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 21534\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#review one data element\n",
        "tokenized_dataset['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmx7ImPNVL9y",
        "outputId": "a7d5aadd-33de-4dee-a206-a439db475ea9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flags': 'BILC',\n",
              " 'utterance': \"I don't have an online account, what do I have to do to register?\",\n",
              " 'category': 'ACCOUNT',\n",
              " 'intent': 13,\n",
              " 'input_ids': [1,\n",
              "  100,\n",
              "  218,\n",
              "  75,\n",
              "  33,\n",
              "  41,\n",
              "  804,\n",
              "  1316,\n",
              "  6,\n",
              "  99,\n",
              "  109,\n",
              "  38,\n",
              "  33,\n",
              "  7,\n",
              "  109,\n",
              "  7,\n",
              "  5124,\n",
              "  116,\n",
              "  2],\n",
              " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator=DataCollatorWithPadding(tokenizer=tokenizer, return_tensors='tf')"
      ],
      "metadata": {
        "id": "OHiwXjaIWQ3T"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert tokenized dataset to tensorflow\n",
        "tf_dataset = tokenized_dataset['train'].to_tf_dataset(\n",
        "    columns = ['input_ids','attention_mask', 'intent'],\n",
        "    shuffle= True,\n",
        "    batch_size= BATCH_SIZE,\n",
        "    collate_fn= data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "_H9kRxNdWlOd"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#swap the postions so o/p intent is after inputs\n",
        "def swap_postions(dataset):\n",
        "  return {'input_ids':dataset['input_ids'],\n",
        "          'attention_mask':dataset['attention_mask'],\n",
        "          }, dataset['intent']"
      ],
      "metadata": {
        "id": "AYFLBfk1XHhC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call the function\n",
        "tf_dataset = tf_dataset.map(swap_postions)"
      ],
      "metadata": {
        "id": "iRs8IlNCXqtA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split train and test dataset\n",
        "train_dataset = tf_dataset.take(int(0.9*len(tf_dataset)))\n",
        "val_dataset = tf_dataset.skip(int(0.9*len(tf_dataset)))"
      ],
      "metadata": {
        "id": "XTxe_GEBXyKg"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#review data\n",
        "for i in val_dataset.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnpyNzLgYNul",
        "outputId": "d5412d7a-bc1d-4872-8295-8edc8491b52d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(16, 25), dtype=int64, numpy=\n",
            "array([[    1,   100,   236,     7, 10061,   127,   804,  1316,     6,\n",
            "          141,    64,    38,   109,    24,   116,     2,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,  7424,    47,  1394,    41,  2936,   141,     7,   120,\n",
            "          103, 12259,   139,  6355,   116,     2,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,  9178,   109,    38,  5312,   127,  1316, 14844,   116,\n",
            "            2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,  7424,   939,  1045,   484,   804,  2349,    19,    10,\n",
            "          881,  1047,   116,     2,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   100,  2740,    10,  1152,     6,    99,    64,    38,\n",
            "          109,     7,   464,   127,  2229,   116,     2,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   100, 23126,   192,    41, 38199,     6,  1137,   162,\n",
            "          141,     7,   109,    24,     2,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,  7424,    38,   192,   110, 22507,   714,   116,     2,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   100, 23126,  6925,    41, 38199,     6,  1137,   162,\n",
            "          147,     7,   109,    24,     2,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,  7424,    47,   311,   162,     5,  2996,   228,  1630,\n",
            "           13,   127,  3682,   116,     2,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   100,    33,    10,   936,  2746,     6,   141,   109,\n",
            "           38, 18981,    24,   116,     2,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   100, 18774,   127, 14844,     6,    99,    64,    38,\n",
            "          109,     7, 18821,    24,   116,     2,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1, 17304,  1717,  1394,    41,  2936,     7,  6296,     9,\n",
            "           10,  3207,   696,     6,  2540,   116,     2,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   100,   236,     7,   216,   147,    38,    64,   464,\n",
            "          127,   645,     2,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,   118,    33,    10,   936,    77,   667,     7,   146,\n",
            "           10,  3207,    19,  1886,     6,    99,   109,   939,    33,\n",
            "            7,   109,     7, 18981,    24,   116,     2],\n",
            "       [    1,  9178,    64,    38, 10061,    10,  2229,   116,     2,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0],\n",
            "       [    1,    29,   677,    41,  2936,   141,     7,  1649,   127,\n",
            "         1087,     2,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(16, 25), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0],\n",
            "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0]])>}, <tf.Tensor: shape=(16,), dtype=int64, numpy=array([25, 22,  8, 13,  9, 22, 26, 22,  7, 23,  8, 23,  9, 23,  2, 24])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n"
      ],
      "metadata": {
        "id": "iWtOCU8XYd-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Based on TFDebertaForSequenceClassification"
      ],
      "metadata": {
        "id": "kzkZpDbpYh6_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Th3i-Az_YeX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}